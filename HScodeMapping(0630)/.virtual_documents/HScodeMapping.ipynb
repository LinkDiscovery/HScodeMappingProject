


import pandas as pd

# CSV 파일 불러오기
file_path = './data/HScode(0630)/basic_data_frame.csv'  # 여기에 실제 파일 경로를 입력하세요
df = pd.read_csv(file_path)


df





import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

# 데이터 로드
file_path = './data/HScode(0630)/basic_data_frame.csv'
df = pd.read_csv(file_path)

# Step 1: 'id' 열을 인덱스로 설정
df.set_index('id', inplace=True)

# Step 2: 사용자 정의 토크나이저를 정의하여 최대 2-gram 생성
def custom_tokenizer(text):
    tokens = text.split()
    ngrams = tokens[:]
    for i in range(len(tokens) - 1):
        ngrams.append(tokens[i] + ' ' + tokens[i+1])
    return ngrams

# Step 3: 사용자 정의 토크나이저를 사용하여 TF-IDF로 벡터화
vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer)
tfidf_matrix = vectorizer.fit_transform(df['DEC_processed'])

# Step 4: TF-IDF 행렬을 데이터프레임으로 변환
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=df.index, columns=vectorizer.get_feature_names_out())

# 결과 데이터프레임 저장
tfidf_df.to_csv('./data/HScode(0630)/TD_IDF_vectorizing.csv')

# 데이터프레임의 크기 확인
print(tfidf_df.shape)


tfidf_df





import pandas as pd

# 업로드된 파일 로드
df1 = pd.read_csv('./data/HScode(0630)/TF_IDF_vectorizing.csv')
df2 = pd.read_csv('./data/HScode(DSC0630)/dsc_vector_data_frame.csv')

# test2_df의 열을 test_df에 추가
combined_df = pd.concat([df1, df2], axis=0)

# 병합된 데이터프레임을 새로운 Excel 파일로 저장
combined_df.to_csv('./data/HScode(DSC0630)/concat_perfect.csv', index=False)


print(combined_df.head())


import pandas as pd
df2 = pd.read_csv('./data/HScode(DSC0630)/dsc_vector_data_frame.csv')
df2


df2


import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

# 데이터 파일 경로 설정
file_path = './data/HScode(DSC0630)/concat_perfect.csv'
# CSV 파일을 읽어서 DataFrame으로 변환
df = pd.read_csv(file_path)
# 'id' 열을 인덱스로 설정
df.set_index('id', inplace=True)

# 행 간의 코사인 유사도 계산
cosine_sim_matrix = cosine_similarity(df)

# 코사인 유사도 행렬을 DataFrame으로 변환하여 가독성 향상
cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=df.index, columns=df.index)

# 결과를 CSV 파일로 저장
csv_file_path = './data/HScode(DSC0630)/Similarity_TD_IDF.csv'
cosine_sim_df.to_csv(csv_file_path, index=False)

# 코사인 유사도 행렬의 처음 30개 행을 출력
cosine_sim_df.head(30)








import pandas as pd

csv_file_path = './data/HScode(DSC0630)/Similarity_TD_IDF.csv'

# CSV 파일 읽기
df = pd.read_csv(csv_file_path)

# 첫 행부터 11446행까지 삭제
df = df.drop(index=df.index[:11447])

# 첫 11448열만 남기기
df = df.iloc[:, :11447]




import pandas as pd

# CSV 파일 경로를 실제 경로로 변경
csv_file_path = './data/HScode(DSC0630)/Similarity_TD_IDF_delet.csv'
df.to_csv(csv_file_path)

print("데이터가 'drop_final.csv' 파일로 저장되었습니다.")


import pandas as pd

# CSV 파일 경로를 실제 경로로 변경
csv_file_path = './data/HScode(DSC0630)/Similarity_TD_IDF_delet.csv'
df = pd.read_csv(csv_file_path)
df





import pandas as pd

csv_file_path = './data/HScode(DSC0630)/Similarity_TD_IDF_delet.csv'

# CSV 파일 읽기
df_latest = pd.read_csv(csv_file_path)

# 각 행에서 가장 높은 값 열 개의 열 이름을 가져오는 함수 정의
def get_top_ten_columns(row):
    sorted_row = row.sort_values(ascending=False)
    return sorted_row.index[:19].tolist()

# 데이터프레임의 각 행에 함수 적용 (첫 번째 열은 인덱스나 식별자로 보이므로 제외)
top_ten_columns_latest = df_latest.iloc[:, 1:].apply(get_top_ten_columns, axis=1)

# 결과를 더 잘 보기 위해 데이터프레임으로 변환
# 인덱스를 살리기 위해 원본 데이터프레임의 인덱스를 사용
top_ten_columns_df_latest = pd.DataFrame(top_ten_columns_latest.tolist(), 
                                         columns=['Top 1', 'Top 2', 'Top 3', 'Top 4', 'Top 5', 'Top 6', 'Top 7', 'Top 8', 'Top 9', 'Top 10',
                                                  'Top 11', 'Top 12', 'Top 13', 'Top 14', 'Top 15', 'Top 16', 'Top 17', 'Top 18', 'Top 19', 'Top 20'
                                                  ,],
                                         index=df_latest.index)



# Save the resulting DataFrame to an Excel file
output_file_path_latest = './data/HScode(DSC0630)/TD_IDF_20.csv'
top_ten_columns_df_latest.to_csv(output_file_path_latest, index=False)

output_file_path_latest


top_ten_columns_df_latest


import pandas as pd

# CSV 파일 경로
csv_file_path = './data/HScode(DSC0630)/TD_IDF_30.csv'

# CSV 파일 읽기
df = pd.read_csv(csv_file_path)

# 랜덤으로 30행 뽑기
random_30_rows = df.sample(n=30, random_state=1)


# Save the resulting DataFrame to an Excel file
output_file_path_latest = './data/HScode(DSC0630)/top30_random_test.csv'
random_30_rows.to_csv(output_file_path_latest, index=False)

output_file_path_latest


import pandas as pd

# 엑셀 파일 경로
file_path = './data/HScode(DSC0630)/modelingverification.xlsx'

# 엑셀 파일의 시트 이름 확인
excel_data = pd.ExcelFile(file_path)
sheet_names = excel_data.sheet_names

# 'iloveyou3' 시트를 데이터프레임으로 불러오기
df = pd.read_excel(file_path)

# HScode와 K_DEC의 매핑을 위한 딕셔너리 생성
hscode_to_kdec = dict(zip(df['HScode'], df['K_DEC']))

# verify_code와 일치하는 HScode를 기반으로 K_DEC 값을 찾는 함수 정의
def find_kdec(verify_code):
    return hscode_to_kdec.get(verify_code, None)

# verify_code 열에 함수를 적용하여 결과를 verify_dec 열에 저장
df['verify_dec'] = df['verify_code'].apply(find_kdec)


# 업데이트된 데이터프레임을 엑셀 파일로 저장
output_file_path = './data/HScode(DSC0630)/modelingverification_updated(최종편집).xlsx'
df.to_excel(output_file_path, index=False)

output_file_path






